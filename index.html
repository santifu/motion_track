<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Detección Dinámica: Pose o Caras</title>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.4/p5.min.js"></script>
    <script src="https://unpkg.com/ml5@0.6.1/dist/ml5.min.js"></script>
    
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            margin: 20px;
            background-color: #f0f0f0;
        }
        h1 {
            color: #333;
            margin-bottom: 20px;
        }
        #p5-canvas-container {
            border: 1px solid #ccc;
            margin-bottom: 20px;
            background-color: #fff;
        }
        #controls {
            background-color: #fff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            width: 640px; /* Match canvas width */
            display: flex;
            flex-direction: column;
            gap: 15px;
            align-items: flex-start; /* Align items to the start for labels */
        }
        .control-group {
            display: flex;
            flex-direction: column;
            gap: 5px;
            width: 100%;
        }
        .control-group label {
            font-weight: bold;
            color: #333;
            margin-bottom: 5px;
        }
        select {
            padding: 8px;
            border-radius: 4px;
            border: 1px solid #ccc;
            width: 100%;
            max-width: 300px; /* Limit width of dropdown */
            font-size: 16px;
        }
        p#status-message {
            color: #555;
            font-style: italic;
        }
    </style>
</head>
<body>
    <h1>Detección Dinámica: Pose o Caras</h1>
    <div id="p5-canvas-container"></div>
    <div id="controls">
        <div class="control-group">
            <label for="detectionType">Selecciona el tipo de detección:</label>
            <select id="detectionType">
                <option value="pose">Detección de Pose (Esqueleto)</option>
                <option value="face">Detección de Caras (Bounding Box y Puntos Clave)</option>
            </select>
        </div>
        <p id="status-message">Cargando modelo...</p>
    </div>

    <script>
        let video;
        let detector; // Can be poseNet or faceapi
        let currentType = 'pose'; // Default detection type
        let poses = []; // For pose detection results
        let faces = []; // For face detection results
        let statusMessageElem; // To display model loading status

        function setup() {
            let canvas = createCanvas(640, 480);
            canvas.parent('p5-canvas-container');

            video = createCapture(VIDEO);
            video.size(width, height);
            video.hide();

            statusMessageElem = select('#status-message'); // Get the HTML element for status messages
            let detectionTypeSelect = select('#detectionType');
            detectionTypeSelect.changed(changeDetectionType); // Add event listener for dropdown change

            // Initial model load
            loadModel(currentType);
        }

        function loadModel(type) {
            // It's good practice to clear existing results when switching models
            poses = [];
            faces = [];
            
            // Re-initialize detector to avoid potential issues with previous model's state
            if (detector) {
                // ml5.js doesn't have a direct 'dispose' or 'stop' for all models,
                // but re-assigning it will usually handle cleanup implicitly
                detector = null; 
            }

            statusMessageElem.html(`Cargando modelo ${type === 'pose' ? 'de PoseNet' : 'de FaceAPI'}... Esto puede tardar un poco.`);
            console.log(`Cargando modelo: ${type}`);

            if (type === 'pose') {
                detector = ml5.poseNet(video, { flipHorizontal: true }, modelReady);
                detector.on('pose', function(results) {
                    poses = results;
                });
            } else if (type === 'face') {
                // IMPORTANT: Set withLandmarks to true to detect facial features
                const detectionOptions = {
                    withLandmarks: true, // This is the key change!
                    withDescriptors: false,
                    // Consider 'tinyFaceDetector' for faster but slightly less accurate face bounding boxes,
                    // especially on lower-end devices or if multiple faces are expected.
                    // detectionNet: 'tinyFaceDetector', 
                };
                detector = ml5.faceApi(video, detectionOptions, modelReady);
                detector.on('detect', function(results) {
                    faces = results;
                });
            }
            currentType = type; // Update current type
        }

        function modelReady() {
            statusMessageElem.html(`Modelo ${currentType === 'pose' ? 'de PoseNet' : 'de FaceAPI'} cargado. ¡Listo para detectar!`);
            console.log(`Modelo ${currentType === 'pose' ? 'de PoseNet' : 'de FaceAPI'} cargado.`);
            // No need to explicitly call detectObjects/detectFaces here, P5.js draw loop handles it
        }

        function changeDetectionType() {
            const selectedType = select('#detectionType').value();
            if (selectedType !== currentType) {
                loadModel(selectedType);
            }
        }

        function draw() {
            // Push/Pop for flipping the video feed
            push();
            translate(width, 0); 
            scale(-1, 1);       
            image(video, 0, 0, width, height); 
            pop(); 

            // Draw based on the currently selected detection type
            if (currentType === 'pose') {
                drawSkeleton();
            } else if (currentType === 'face') {
                drawFaces();
            }
        }

        // --- Pose Detection Drawing Functions ---
        function drawSkeleton() {
            for (let i = 0; i < poses.length; i++) {
                let pose = poses[i].pose;
                let skeleton = poses[i].skeleton;

                // Draw keypoints
                for (let j = 0; j < pose.keypoints.length; j++) {
                    let keypoint = pose.keypoints[j];
                    if (keypoint.score > 0.2) {
                        fill(255, 0, 0); // Red
                        noStroke();
                        ellipse(keypoint.position.x, keypoint.position.y, 10, 10);
                    }
                }

                // Draw skeleton connections
                for (let j = 0; j < skeleton.length; j++) {
                    let partA = skeleton[j][0];
                    let partB = skeleton[j][1];
                    stroke(0, 255, 0); // Green
                    strokeWeight(3);
                    line(partA.position.x, partA.position.y, partB.position.x, partB.position.y);
                }
            }
        }

        // --- Face Detection Drawing Functions ---
        function drawFaces() {
            for (let i = 0; i < faces.length; i++) {
                let face = faces[i];
                let box = face.alignedRect._box; // Bounding box for the face

                stroke(0, 0, 255); // Blue bounding box
                strokeWeight(2);
                noFill();
                rect(box.x, box.y, box.width, box.height);

                // Draw facial landmarks (eyes, nose, mouth, eyebrows, jawline)
                drawLandmarks(face.landmarks);
            }
        }

        // Helper function to draw facial landmarks
        function drawLandmarks(landmarks) {
            noFill();
            stroke(255, 255, 0); // Yellow for landmarks
            strokeWeight(2);

            // Jawline
            beginShape();
            for (let i = 0; i < landmarks.positions.length; i++) {
                if (i >= 0 && i <= 16) { // Jawline points
                    vertex(landmarks.positions[i]._x, landmarks.positions[i]._y);
                }
            }
            endShape();

            // Eyebrows
            for (let i = 17; i <= 26; i++) {
                ellipse(landmarks.positions[i]._x, landmarks.positions[i]._y, 4, 4);
            }
            
            // Nose
            beginShape();
            for (let i = 27; i <= 35; i++) {
                vertex(landmarks.positions[i]._x, landmarks.positions[i]._y);
            }
            endShape();

            // Eyes
            // Right eye (your left)
            beginShape();
            for (let i = 36; i <= 41; i++) {
                vertex(landmarks.positions[i]._x, landmarks.positions[i]._y);
            }
            endShape(CLOSE);

            // Left eye (your right)
            beginShape();
            for (let i = 42; i <= 47; i++) {
                vertex(landmarks.positions[i]._x, landmarks.positions[i]._y);
            }
            endShape(CLOSE);

            // Mouth
            beginShape();
            for (let i = 48; i <= 60; i++) {
                vertex(landmarks.positions[i]._x, landmarks.positions[i]._y);
            }
            endShape(CLOSE);
            
            beginShape(); // Inner mouth contour
            for (let i = 61; i <= 67; i++) {
                vertex(landmarks.positions[i]._x, landmarks.positions[i]._y);
            }
            endShape(CLOSE);
        }


        // Optional: Error handling for video capture (though P5.js handles some)
        function videoError(err) {
            console.error("Error accessing video stream:", err);
            alert("No se pudo acceder a la cámara. Asegúrate de dar permiso y de que no esté siendo usada por otra aplicación.");
        }
    </script>
</body>
</html>
