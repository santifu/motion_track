<!DOCTYPE html>
<html>
<head>
    <title>Detección de Caras con OpenCV.js</title>
    <script src="opencv.js" async onload="onOpenCvReady();"></script>
    <style>
        body {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
            background-color: #f0f0f0;
        }
        #videoInput {
            max-width: 80%;
            height: auto;
            border: 1px solid #ccc;
        }
        #canvasOutput {
            max-width: 80%;
            height: auto;
            border: 1px solid #ccc;
            margin-top: 10px;
        }
    </style>
</head>
<body>
    <h1>Detección de Caras con OpenCV.js</h1>
    <video id="videoInput" autoplay playsinline></video>
    <canvas id="canvasOutput"></canvas>
    <script>
        let video = document.getElementById('videoInput');
        let canvas = document.getElementById('canvasOutput');
        let ctx = canvas.getContext('2d');
        let faceCascade;
        let utils;

        function onOpenCvReady() {
            console.log("OpenCV.js is ready.");
             utils = new Utils('errorMessage');
            utils.loadOpenCv(() => {
                faceCascade = new cv.CascadeClassifier();
                // Utiliza una URL CDN para cargar el archivo haarcascade_frontalface_default.xml
                utils.createFileFromURL('haarcascade_frontalface_default.xml', 'https://cdn.jsdelivr.net/npm/opencv@4.0.0/data/haarcascades/haarcascade_frontalface_default.xml', () => {
                    console.log("haarcascade_frontalface_default.xml loaded");
                    startCamera();
                });
            });
        }

        function startCamera() {
            navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio: false })
                .then(function(stream) {
                    video.srcObject = stream;
                    video.play();
                    processVideo();
                })
                .catch(function(err) {
                    console.log("An error occurred! " + err);
                });
        }

        function processVideo() {
            let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
            let dst = new cv.Mat(video.height, video.width, cv.CV_8UC4);
            let gray = new cv.Mat();

            function detectFaces() {
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
                dst = new cv.Mat(video.height, video.width, cv.CV_8UC4);
                gray = new cv.Mat();
                src = utils.createMatFromVideo(video,src);
                cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
                let faces = new cv.RectVector();
                faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0);

                for (let i = 0; i < faces.size(); ++i) {
                    let face = faces.get(i);
                    let point1 = new cv.Point(face.x, face.y);
                    let point2 = new cv.Point(face.x + face.width, face.y + face.height);
                    cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);
                }
                cv.imshow('canvasOutput', dst);
                src.delete();
                dst.delete();
                gray.delete();
                faces.delete();
            }

            (function frameLooper() {
                window.requestAnimationFrame(frameLooper);
                detectFaces();
            })();
        }
    </script>
</body>
</html>
